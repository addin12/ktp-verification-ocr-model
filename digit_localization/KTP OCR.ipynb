{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "211cdb8f",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "109820ef-774e-44b9-93ca-5c1a13509e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 07:59:27.893745: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-24 07:59:27.893788: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib\n",
    "# matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import PIL.ImageColor as ImageColor\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "import PIL.ImageFont as ImageFont\n",
    "from IPython.display import display\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "# sys.path.append(\"..\")\n",
    "\n",
    "# Import utilities\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5b3aef-22d7-4662-a4fe-ae7209c59e43",
   "metadata": {},
   "source": [
    "## Define Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d5db7f-b254-4d85-8d81-762a0106ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digit Prediction functions methods definition\n",
    "\n",
    "def convert_range(prediction_score, OldMin, OldMax):\n",
    "    NewMax = 1\n",
    "    NewMin = 0\n",
    "    \n",
    "    OldRange = (OldMax - OldMin)  \n",
    "    NewRange = (NewMax - NewMin)  \n",
    "    NewValue = (((prediction_score - OldMin) * NewRange) / OldRange) + NewMin\n",
    "    return NewValue\n",
    "\n",
    "def get_prediction_s(image_dir, model_name):\n",
    "    test_img = tf.keras.utils.load_img(image_dir,\n",
    "                                   grayscale = False,\n",
    "                                   color_mode = 'rgb',\n",
    "                                   target_size = (160,160,3),\n",
    "                                   interpolation = 'nearest')\n",
    "    img_array = tf.keras.utils.img_to_array(test_img)\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "    predictions = model_name.predict(img_array)\n",
    "    score = predictions[0]\n",
    "    \n",
    "    class_names = [int(i) for i in range(10)]\n",
    "    pred_label = class_names[np.argmax(score)]\n",
    "    \n",
    "    conf_score = np.max(score)\n",
    "    model_score = np.max(score)\n",
    "    \n",
    "    return pred_label, conf_score, model_score,score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c2337e-41c0-40d5-ba9d-7d92bd753b51",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d82c16f",
   "metadata": {},
   "source": [
    "### Load Localization Model & Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f778043a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 08:02:10.495908: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2022-10-24 08:02:10.495955: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-24 08:02:10.495981: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (addin-gurihmas-dev): /proc/driver/nvidia/version does not exist\n",
      "2022-10-24 08:02:10.496476: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Load the label map.\n",
    "# Label maps map indices to category names, so that when our convolution\n",
    "# network predicts `5`, we know that this corresponds to `king`.\n",
    "# Here we use internal utility functions, but anything that returns a\n",
    "# dictionary mapping integers to appropriate string labels would be fine\n",
    "# Grab path to current working directory\n",
    "\n",
    "CWD_PATH = os.getcwd()\n",
    "\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "# Name of the directory containing the object detection module we're using\n",
    "MODEL_NAME = 'inference_graph'\n",
    "\n",
    "# Path to frozen detection graph .pb file, which contains the model that is used\n",
    "# for object detection.\n",
    "PATH_TO_CKPT = os.path.join(CWD_PATH,'ml_models',MODEL_NAME,'221005_frozen_inference_graph.pb')\n",
    "\n",
    "# Path to label map file\n",
    "PATH_TO_LABELS = os.path.join(CWD_PATH,'training','labelmap.pbtxt')\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "# Load the Tensorflow model into memory.\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.compat.v1.GraphDef()\n",
    "    with tf.compat.v2.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "    sess = tf.compat.v1.Session(graph=detection_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71f90620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define input and output tensors (i.e. data) for the object detection classifier\n",
    "\n",
    "# Input tensor is the image\n",
    "image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "# Output tensors are the detection boxes, scores, and classes\n",
    "# Each box represents a part of the image where a particular object was detected\n",
    "detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "\n",
    "# Each score represents level of confidence for each of the objects.\n",
    "# The score is shown on the result image, together with the class label.\n",
    "detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "\n",
    "# Number of objects detected\n",
    "num_detections = detection_graph.get_tensor_by_name('num_detections:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849290f2-ba59-4846-b410-b88055dd487c",
   "metadata": {},
   "source": [
    "### Load Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74fc3adc-ec68-459d-a706-eea35bf9ad8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 160, 160, 3)]     0         \n",
      "_________________________________________________________________\n",
      "tf.math.truediv (TFOpLambda) (None, 160, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda (None, 160, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_160 (Functi (None, 5, 5, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                12810     \n",
      "=================================================================\n",
      "Total params: 2,270,794\n",
      "Trainable params: 1,874,250\n",
      "Non-trainable params: 396,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load digit prediction trained model\n",
    "model = tf.keras.models.load_model(os.path.join(CWD_PATH,'ml_models','DR_MobileNetV2_v3.h5'))\n",
    "\n",
    "# Show the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ae20b3-c96b-470c-a686-9fe9466083cc",
   "metadata": {},
   "source": [
    "## List Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79f0141f-1419-42b3-8ff6-fd4cf9d4b97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0068ef20-1d1b-4961-af65-7d9d0a0897cc.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006404a7-81d4-4d8c-9dbe-ce3c8f4df4e8.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00ffe211-568a-4345-ba25-0829863d0f7d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>006002a2-1345-4e49-97c5-f3b08f01852e.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003e5596-fa43-48ae-b5ce-5fd389d25128.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   filename\n",
       "0  0068ef20-1d1b-4961-af65-7d9d0a0897cc.jpg\n",
       "1  006404a7-81d4-4d8c-9dbe-ce3c8f4df4e8.jpg\n",
       "2  00ffe211-568a-4345-ba25-0829863d0f7d.jpg\n",
       "3  006002a2-1345-4e49-97c5-f3b08f01852e.jpg\n",
       "4  003e5596-fa43-48ae-b5ce-5fd389d25128.jpg"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_crop = os.listdir(os.path.join(CWD_PATH,'image_samples/image_asli_added'))\n",
    "data_to_crop = pd.DataFrame(data_to_crop,columns=['filename'])\n",
    "data_to_crop.to_csv('/home/jupyter/gurih_mas/OCR/results/221018_filename_result.csv',index=False)\n",
    "print(data_to_crop.shape)\n",
    "data_to_crop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc503cb",
   "metadata": {},
   "source": [
    "## Localize Digit Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9874c2c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2022-10-21 06:20:55.580320: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -7 } dim { size: -10 } dim { size: -12 } dim { size: 576 } } } inputs { dtype: DT_FLOAT shape { dim { size: -37 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -37 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } tensor_content: \"\\016\\000\\000\\000\\016\\000\\000\\000\" } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"111\" frequency: 2199 num_cores: 4 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.3.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 57671680 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -37 } dim { size: 14 } dim { size: 14 } dim { size: 576 } } }\n",
      "100%|██████████| 300/300 [05:35<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "CWD_PATH = os.getcwd()\n",
    "image_path = os.path.join(CWD_PATH,'image_samples/image_asli_added')\n",
    "image_cropped_path = os.path.join(CWD_PATH,'image_samples/cropped_image')\n",
    "image_localized_path = os.path.join(CWD_PATH,'image_samples/localized_image')\n",
    "digit_dataset_path = os.path.join(CWD_PATH,'image_samples/digit_dataset')\n",
    "\n",
    "filename_list = []\n",
    "filename_crop_list = [] \n",
    "ymin_list = []\n",
    "ymax_list = []\n",
    "xmin_list = []\n",
    "xmax_list = []\n",
    "width_list = []\n",
    "height_list = []\n",
    "\n",
    "# IMAGE_NAME = '10b189c6-8a5a-400d-9734-1800be3466d4.jpg'\n",
    "\n",
    "for i in tqdm(range(data_to_crop.shape[0])):\n",
    "    IMAGE_NAME = data_to_crop.filename[i]\n",
    "    image_name_raw = IMAGE_NAME.split('.')[-2]\n",
    "    \n",
    "    # PATH_TO_IMAGE = os.path.join(CWD_PATH,'sampel_gambar','sample_data_real_test',IMAGE_NAME)\n",
    "    PATH_TO_IMAGE = os.path.join(image_path,IMAGE_NAME)\n",
    "    \n",
    "    image = cv2.imread(PATH_TO_IMAGE)\n",
    "    raw_image = cv2.imread(PATH_TO_IMAGE)\n",
    "    height, width, channels = image.shape\n",
    "    \n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_expanded = np.expand_dims(image_rgb, axis=0)\n",
    "    \n",
    "    (boxes, scores, classes, num) = sess.run(\n",
    "        [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "        feed_dict={image_tensor: image_expanded})\n",
    "\n",
    "    final_image, bbox = vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image,\n",
    "        np.squeeze(boxes),\n",
    "        np.squeeze(classes).astype(np.int32),\n",
    "        np.squeeze(scores),\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=3,\n",
    "        min_score_thresh=0.95)\n",
    "\n",
    "    # display(Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)))\n",
    "    im = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    im.save(image_localized_path+'/{}.jpg'.format(image_name_raw,i))\n",
    "\n",
    "    bbox.sort(reverse=False)\n",
    "\n",
    "    for i in range(len(bbox)):\n",
    "        xmin = bbox[i][0]\n",
    "        ymin = bbox[i][1]\n",
    "        xmax = bbox[i][2]\n",
    "        ymax = bbox[i][3]\n",
    "\n",
    "        filename_list.append(IMAGE_NAME)\n",
    "        ymin_list.append(ymin)\n",
    "        xmin_list.append(xmin)\n",
    "        ymax_list.append(ymax)\n",
    "        xmax_list.append(xmax)\n",
    "        width_list.append(width)\n",
    "        height_list.append(height)\n",
    "\n",
    "        cropped_img = raw_image[ymin:ymax,xmin:xmax]\n",
    "        rgb_cropped_img = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # display(Image.fromarray(rgb_cropped_img))\n",
    "        im_crop = Image.fromarray(rgb_cropped_img)\n",
    "        im_crop.save(image_cropped_path+'/{}_{}.jpg'.format(image_name_raw,i))\n",
    "        filename_crop_list.append('{}_{}.jpg'.format(image_name_raw,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14639652-13e2-447f-b1f2-dd09d530f254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cropped images: (3825, 2)\n"
     ]
    }
   ],
   "source": [
    "summary_df = pd.DataFrame([])\n",
    "summary_df['filename_ktp'] = filename_list\n",
    "summary_df['filename_digit'] = filename_crop_list\n",
    "print('Total cropped images: {}'.format(summary_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cbb7530-ca7a-46e8-ba3c-9491657db61d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_df.to_csv(os.path.join(CWD_PATH,'image_samples/221018_added_cropped_result.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e018bf7-2e32-4763-9a24-1b56d1392f01",
   "metadata": {},
   "source": [
    "## Predict Digit Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10f43b29-7eff-4b27-8ff7-b5167bd6f9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3825 [00:00<?, ?it/s]2022-10-21 06:26:31.014051: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "100%|██████████| 3825/3825 [03:24<00:00, 18.74it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_label=[]\n",
    "scoring=[]\n",
    "\n",
    "for i in tqdm(range(len(filename_crop_list))):\n",
    "    image_filename = filename_crop_list[i]\n",
    "    image_full_path_dir = '{}/{}'.format(image_cropped_path, image_filename)\n",
    "\n",
    "    try:\n",
    "        pred_label_s, conf_score_s, model_score_s,score = get_prediction_s(image_full_path_dir, model)\n",
    "        pred_label.append(pred_label_s)\n",
    "        scoring.append(conf_score_s)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d095034-742e-4167-9972-3647b8ea8813",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted images: (3825, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename_ktp</th>\n",
       "      <th>filename_digit</th>\n",
       "      <th>pred_score</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0068ef20-1d1b-4961-af65-7d9d0a0897cc.jpg</td>\n",
       "      <td>0068ef20-1d1b-4961-af65-7d9d0a0897cc_0.jpg</td>\n",
       "      <td>0.999660</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0068ef20-1d1b-4961-af65-7d9d0a0897cc.jpg</td>\n",
       "      <td>0068ef20-1d1b-4961-af65-7d9d0a0897cc_1.jpg</td>\n",
       "      <td>0.999271</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0068ef20-1d1b-4961-af65-7d9d0a0897cc.jpg</td>\n",
       "      <td>0068ef20-1d1b-4961-af65-7d9d0a0897cc_2.jpg</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0068ef20-1d1b-4961-af65-7d9d0a0897cc.jpg</td>\n",
       "      <td>0068ef20-1d1b-4961-af65-7d9d0a0897cc_3.jpg</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0068ef20-1d1b-4961-af65-7d9d0a0897cc.jpg</td>\n",
       "      <td>0068ef20-1d1b-4961-af65-7d9d0a0897cc_4.jpg</td>\n",
       "      <td>0.999856</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               filename_ktp  \\\n",
       "0  0068ef20-1d1b-4961-af65-7d9d0a0897cc.jpg   \n",
       "1  0068ef20-1d1b-4961-af65-7d9d0a0897cc.jpg   \n",
       "2  0068ef20-1d1b-4961-af65-7d9d0a0897cc.jpg   \n",
       "3  0068ef20-1d1b-4961-af65-7d9d0a0897cc.jpg   \n",
       "4  0068ef20-1d1b-4961-af65-7d9d0a0897cc.jpg   \n",
       "\n",
       "                               filename_digit  pred_score  pred_label  \n",
       "0  0068ef20-1d1b-4961-af65-7d9d0a0897cc_0.jpg    0.999660           3  \n",
       "1  0068ef20-1d1b-4961-af65-7d9d0a0897cc_1.jpg    0.999271           5  \n",
       "2  0068ef20-1d1b-4961-af65-7d9d0a0897cc_2.jpg    1.000000           0  \n",
       "3  0068ef20-1d1b-4961-af65-7d9d0a0897cc_3.jpg    1.000000           7  \n",
       "4  0068ef20-1d1b-4961-af65-7d9d0a0897cc_4.jpg    0.999856           1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df['pred_score'] = scoring\n",
    "summary_df['pred_label'] = pred_label\n",
    "print('Predicted images: {}'.format(summary_df.shape))\n",
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0bd69b7-b1c7-4bf9-ba29-740eaab526ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_df.to_csv(os.path.join(CWD_PATH,'image_samples/221018_added_prediction_result.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6146cd28-5afe-42c1-94b7-b377e71bdba2",
   "metadata": {},
   "source": [
    "## Copy predicted images to each labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a93b555f-c9de-4859-85cd-a5b296a5fb0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_names = [str(i) for i in range(10)]\n",
    "\n",
    "for c in class_names:\n",
    "    if os.path.isdir(os.path.join(digit_dataset_path,c)) == False:\n",
    "        os.makedirs(os.path.join(digit_dataset_path,c))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df942272-050e-4c21-bd2e-c0f2202783f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3825/3825 [00:00<00:00, 55746.44it/s]\n"
     ]
    }
   ],
   "source": [
    "#Copy images based on labels\n",
    "\n",
    "for i in tqdm(range(summary_df.shape[0])):\n",
    "    img = summary_df['filename_digit'][i]\n",
    "    label = str(summary_df['pred_label'][i])\n",
    "    source_final_path = os.path.join(image_cropped_path,img)\n",
    "    dest_final_path = os.path.join(digit_dataset_path,label,img)\n",
    "    if os.path.isfile(dest_final_path) == False:\n",
    "        shutil.copy(source_final_path,dest_final_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b51965-7029-4cf1-b3b6-7b505a9ea210",
   "metadata": {},
   "source": [
    "## Summarize digit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a99c569-8903-43c1-9373-4dc74088c09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1646\n",
       "1     471\n",
       "2     258\n",
       "3     435\n",
       "4      98\n",
       "5     238\n",
       "6     147\n",
       "7     256\n",
       "8     123\n",
       "9     153\n",
       "Name: pred_label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df.pred_label.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3f47c16-9859-4257-b059-0094896d322e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename_digit</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0068f939-87a8-43e6-b5f1-202173afe9cc_13.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002409f6-cfc7-494c-ad42-ba82ec1fc0c7_13.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002409f6-cfc7-494c-ad42-ba82ec1fc0c7_14.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01717470-8425-431c-bf42-f048957329be_3.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01717470-8425-431c-bf42-f048957329be_4.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>01523787-3ec3-4160-bfcc-6faeda7b2ff3_10.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3821</th>\n",
       "      <td>00a985d0-6125-4b14-88a7-5c6a895d5eb9_11.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3822</th>\n",
       "      <td>0097eec9-3806-42e0-9308-44ec0703e7dd_5.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823</th>\n",
       "      <td>0123f301-2ec5-45e5-bf63-ffb79c16e252_9.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824</th>\n",
       "      <td>012dc63f-ea73-4869-9442-6783a8a44dce_7.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3825 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   filename_digit  pred_label\n",
       "0     0068f939-87a8-43e6-b5f1-202173afe9cc_13.jpg           0\n",
       "1     002409f6-cfc7-494c-ad42-ba82ec1fc0c7_13.jpg           0\n",
       "2     002409f6-cfc7-494c-ad42-ba82ec1fc0c7_14.jpg           0\n",
       "3      01717470-8425-431c-bf42-f048957329be_3.jpg           0\n",
       "4      01717470-8425-431c-bf42-f048957329be_4.jpg           0\n",
       "...                                           ...         ...\n",
       "3820  01523787-3ec3-4160-bfcc-6faeda7b2ff3_10.jpg           9\n",
       "3821  00a985d0-6125-4b14-88a7-5c6a895d5eb9_11.jpg           9\n",
       "3822   0097eec9-3806-42e0-9308-44ec0703e7dd_5.jpg           9\n",
       "3823   0123f301-2ec5-45e5-bf63-ffb79c16e252_9.jpg           9\n",
       "3824   012dc63f-ea73-4869-9442-6783a8a44dce_7.jpg           9\n",
       "\n",
       "[3825 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_digit = summary_df.filter(['filename_digit','pred_label'], axis=1).sort_values('pred_label').reset_index(drop=True)\n",
    "df_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1698b62-8522-4a42-bb9c-3dd2e99a0c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(df_digit.pred_label.unique()) #Create a Python list of Unique labels in data frame labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e98aa5c2-2f1b-4f0b-9e87-575c1c752703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataframe into multiple dataframe based on unique column values\n",
    "dfdigit0 = df_digit.loc[df_digit['pred_label'] == 0]\n",
    "dfdigit0 = dfdigit0[0:146]\n",
    "dfdigit3 = df_digit.loc[df_digit['pred_label'] == 3]\n",
    "dfdigit3 = dfdigit3[0:114]\n",
    "dfdigit9 = df_digit.loc[df_digit['pred_label'] == 9]\n",
    "dfdigit9 = dfdigit9[0:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8c0dae8-e458-49f1-af41-adc2f4f3149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting images for each PIC\n",
    "pic = ['Addin', 'Vanda']\n",
    "list_pic0 = []\n",
    "list_pic3 = []\n",
    "list_pic9 = []\n",
    "\n",
    "for member in pic :\n",
    "    for i in range(int(146/2)):\n",
    "        list_pic0.append(member)\n",
    "dfdigit0['PIC'] = list_pic0\n",
    "\n",
    "for member in pic :\n",
    "    for i in range(int(114/2)):\n",
    "        list_pic3.append(member)\n",
    "dfdigit3['PIC'] = list_pic3\n",
    "\n",
    "for member in pic :\n",
    "    for i in range(int(150/2)):\n",
    "        list_pic9.append(member)\n",
    "dfdigit9['PIC'] = list_pic9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4db64dca-26ac-4e63-a096-dd90c72b7efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    146\n",
       "3    114\n",
       "9    150\n",
       "Name: pred_label, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_dataset = pd.concat([dfdigit0, dfdigit3, dfdigit9], axis=0).reset_index(drop=True)\n",
    "filename_dataset.to_csv('221018_Added_Image_Samples.csv', index=False)\n",
    "filename_dataset.pred_label.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74b5dca3-ecf0-4d50-97f7-692a8494e88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Addin    205\n",
       "Vanda    205\n",
       "Name: PIC, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_dataset.PIC.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "525f82e8-792a-4d06-9f5c-be5781653504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename_digit</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>PIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0068f939-87a8-43e6-b5f1-202173afe9cc_13.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Addin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002409f6-cfc7-494c-ad42-ba82ec1fc0c7_13.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Addin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002409f6-cfc7-494c-ad42-ba82ec1fc0c7_14.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Addin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01717470-8425-431c-bf42-f048957329be_3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Addin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01717470-8425-431c-bf42-f048957329be_4.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Addin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0123f301-2ec5-45e5-bf63-ffb79c16e252_11.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>Vanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>00a985d0-6125-4b14-88a7-5c6a895d5eb9_10.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>Vanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>00e8f929-b97c-4dd7-b34e-dd63a497f642_2.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>Vanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>01523787-3ec3-4160-bfcc-6faeda7b2ff3_10.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>Vanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>00a985d0-6125-4b14-88a7-5c6a895d5eb9_11.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>Vanda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  filename_digit  pred_label    PIC\n",
       "0    0068f939-87a8-43e6-b5f1-202173afe9cc_13.jpg           0  Addin\n",
       "1    002409f6-cfc7-494c-ad42-ba82ec1fc0c7_13.jpg           0  Addin\n",
       "2    002409f6-cfc7-494c-ad42-ba82ec1fc0c7_14.jpg           0  Addin\n",
       "3     01717470-8425-431c-bf42-f048957329be_3.jpg           0  Addin\n",
       "4     01717470-8425-431c-bf42-f048957329be_4.jpg           0  Addin\n",
       "..                                           ...         ...    ...\n",
       "405  0123f301-2ec5-45e5-bf63-ffb79c16e252_11.jpg           9  Vanda\n",
       "406  00a985d0-6125-4b14-88a7-5c6a895d5eb9_10.jpg           9  Vanda\n",
       "407   00e8f929-b97c-4dd7-b34e-dd63a497f642_2.jpg           9  Vanda\n",
       "408  01523787-3ec3-4160-bfcc-6faeda7b2ff3_10.jpg           9  Vanda\n",
       "409  00a985d0-6125-4b14-88a7-5c6a895d5eb9_11.jpg           9  Vanda\n",
       "\n",
       "[410 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e34ee9-ea54-4584-b52f-7ba093628068",
   "metadata": {},
   "source": [
    "### Split images to each PIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "476a82db-0b3e-4c62-96a9-f5759382170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for each PIC\n",
    "class_names = [str(i) for i in range(10)]\n",
    "pic = ['Addin', 'Vanda']\n",
    "\n",
    "for p in pic:\n",
    "    for c in class_names:\n",
    "        if os.path.isdir(os.path.join('/home/jupyter/gurih_mas/OCR/image_samples',p,c)) == False:\n",
    "            os.makedirs(os.path.join('/home/jupyter/gurih_mas/OCR/image_samples',p,c))\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2535ec6-4590-451f-afad-5525d7e77c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 410/410 [00:00<00:00, 7244.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# Copy images based on PIC\n",
    "\n",
    "dest_path = '/home/jupyter/gurih_mas/OCR/image_samples'\n",
    "\n",
    "for i in tqdm(range(filename_dataset.shape[0])):\n",
    "    img = filename_dataset['filename_digit'][i]\n",
    "    pic = filename_dataset['PIC'][i]\n",
    "    label = str(filename_dataset['pred_label'][i])\n",
    "    source_final_path = os.path.join(image_cropped_path,img)\n",
    "    dest_final_path = os.path.join(dest_path,pic,label,img)\n",
    "    if os.path.isfile(dest_final_path) == False:\n",
    "        shutil.copy(source_final_path,dest_final_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "defa3648-0e3e-4418-96df-d2168c937c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "pic = ['Mas Kemas', 'Addin', 'Krisna', 'Rio', 'Vanda']\n",
    "\n",
    "def zipdir(path, ziph):\n",
    "    # ziph is zipfile handle\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            ziph.write(os.path.join(root, file), \n",
    "                       os.path.relpath(os.path.join(root, file), \n",
    "                                       os.path.join(path, '..')))\n",
    "\n",
    "for p in pic :\n",
    "    with zipfile.ZipFile('/home/jupyter/OCR/addin/digit_localization_prediction_model/{}.zip'.format(p), 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        zipdir('/home/jupyter/OCR/addin/digit_localization_prediction_model/sampel_gambar/221018_dataset/{}'.format(p), zipf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61d2f632-1377-42a6-858d-68d491eb33a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_archive(source, destination):\n",
    "    base = os.path.basename(destination)\n",
    "    name = base.split('.')[0]\n",
    "    format = base.split('.')[1]\n",
    "    archive_from = os.path.dirname(source)\n",
    "    archive_to = os.path.basename(source.strip(os.sep))\n",
    "    print(source, destination, archive_from, archive_to)\n",
    "    shutil.make_archive(name, format, archive_from, archive_to)\n",
    "    shutil.move('%s.%s'%(name,format), destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5afe6b88-dcc4-4ee5-95a2-2223204b5c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/gurih_mas/OCR/image_samples/Addin /home/jupyter/gurih_mas/OCR/Addin.zip /home/jupyter/gurih_mas/OCR/image_samples Addin\n",
      "/home/jupyter/gurih_mas/OCR/image_samples/Vanda /home/jupyter/gurih_mas/OCR/Vanda.zip /home/jupyter/gurih_mas/OCR/image_samples Vanda\n"
     ]
    }
   ],
   "source": [
    "pic = ['Addin', 'Vanda']\n",
    "\n",
    "for p in pic :\n",
    "    make_archive(os.path.join('/home/jupyter/gurih_mas/OCR/image_samples/pic_split/221018_added_dataset',p), '/home/jupyter/gurih_mas/OCR/image_samples/pic_split/221018_added_dataset/{}.zip'.format(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024bb7c6-c43c-4f72-a1b1-6052d9e27c19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
