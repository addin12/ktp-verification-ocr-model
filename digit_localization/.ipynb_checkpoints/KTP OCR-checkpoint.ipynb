{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "211cdb8f",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "109820ef-774e-44b9-93ca-5c1a13509e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-21 04:15:04.372401: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-21 04:15:04.372454: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib\n",
    "# matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import PIL.ImageColor as ImageColor\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "import PIL.ImageFont as ImageFont\n",
    "from IPython.display import display\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "# sys.path.append(\"..\")\n",
    "\n",
    "# Import utilities\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5b3aef-22d7-4662-a4fe-ae7209c59e43",
   "metadata": {},
   "source": [
    "## Define Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d5db7f-b254-4d85-8d81-762a0106ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digit Prediction functions methods definition\n",
    "\n",
    "def convert_range(prediction_score, OldMin, OldMax):\n",
    "    NewMax = 1\n",
    "    NewMin = 0\n",
    "    \n",
    "    OldRange = (OldMax - OldMin)  \n",
    "    NewRange = (NewMax - NewMin)  \n",
    "    NewValue = (((prediction_score - OldMin) * NewRange) / OldRange) + NewMin\n",
    "    return NewValue\n",
    "\n",
    "def get_prediction_s(image_dir, model_name):\n",
    "    test_img = tf.keras.utils.load_img(image_dir,\n",
    "                                   grayscale = False,\n",
    "                                   color_mode = 'rgb',\n",
    "                                   target_size = (160,160,3),\n",
    "                                   interpolation = 'nearest')\n",
    "    img_array = tf.keras.utils.img_to_array(test_img)\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "    predictions = model_name.predict(img_array)\n",
    "    score = predictions[0]\n",
    "    \n",
    "    class_names = [int(i) for i in range(10)]\n",
    "    pred_label = class_names[np.argmax(score)]\n",
    "    \n",
    "    conf_score = np.max(score)\n",
    "    model_score = np.max(score)\n",
    "    \n",
    "    return pred_label, conf_score, model_score,score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c2337e-41c0-40d5-ba9d-7d92bd753b51",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d82c16f",
   "metadata": {},
   "source": [
    "### Load Localization Model & Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f778043a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-21 04:15:29.112227: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2022-10-21 04:15:29.112289: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-21 04:15:29.112330: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (addin-gurihmas-dev): /proc/driver/nvidia/version does not exist\n",
      "2022-10-21 04:15:29.112867: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Load the label map.\n",
    "# Label maps map indices to category names, so that when our convolution\n",
    "# network predicts `5`, we know that this corresponds to `king`.\n",
    "# Here we use internal utility functions, but anything that returns a\n",
    "# dictionary mapping integers to appropriate string labels would be fine\n",
    "# Grab path to current working directory\n",
    "\n",
    "CWD_PATH = os.getcwd()\n",
    "\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "# Name of the directory containing the object detection module we're using\n",
    "MODEL_NAME = 'inference_graph'\n",
    "\n",
    "# Path to frozen detection graph .pb file, which contains the model that is used\n",
    "# for object detection.\n",
    "PATH_TO_CKPT = os.path.join(CWD_PATH,'ml_models',MODEL_NAME,'221005_frozen_inference_graph.pb')\n",
    "\n",
    "# Path to label map file\n",
    "PATH_TO_LABELS = os.path.join(CWD_PATH,'training','labelmap.pbtxt')\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "# Load the Tensorflow model into memory.\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.compat.v1.GraphDef()\n",
    "    with tf.compat.v2.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "    sess = tf.compat.v1.Session(graph=detection_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71f90620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define input and output tensors (i.e. data) for the object detection classifier\n",
    "\n",
    "# Input tensor is the image\n",
    "image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "# Output tensors are the detection boxes, scores, and classes\n",
    "# Each box represents a part of the image where a particular object was detected\n",
    "detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "\n",
    "# Each score represents level of confidence for each of the objects.\n",
    "# The score is shown on the result image, together with the class label.\n",
    "detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "\n",
    "# Number of objects detected\n",
    "num_detections = detection_graph.get_tensor_by_name('num_detections:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849290f2-ba59-4846-b410-b88055dd487c",
   "metadata": {},
   "source": [
    "### Load Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74fc3adc-ec68-459d-a706-eea35bf9ad8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 160, 160, 3)]     0         \n",
      "_________________________________________________________________\n",
      "tf.math.truediv_1 (TFOpLambd (None, 160, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_1 (TFOpLamb (None, 160, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_160 (Functi (None, 5, 5, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                12810     \n",
      "=================================================================\n",
      "Total params: 2,270,794\n",
      "Trainable params: 1,874,250\n",
      "Non-trainable params: 396,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load digit prediction trained model\n",
    "model = tf.keras.models.load_model(os.path.join(CWD_PATH,'ml_models','DR_MobileNetV2_v2.0.h5'))\n",
    "\n",
    "# Show the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ae20b3-c96b-470c-a686-9fe9466083cc",
   "metadata": {},
   "source": [
    "## List Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79f0141f-1419-42b3-8ff6-fd4cf9d4b97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0068ef20-1d1b-4961-af65-7d9d0a0897cc.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006404a7-81d4-4d8c-9dbe-ce3c8f4df4e8.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00ffe211-568a-4345-ba25-0829863d0f7d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>006002a2-1345-4e49-97c5-f3b08f01852e.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003e5596-fa43-48ae-b5ce-5fd389d25128.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   filename\n",
       "0  0068ef20-1d1b-4961-af65-7d9d0a0897cc.jpg\n",
       "1  006404a7-81d4-4d8c-9dbe-ce3c8f4df4e8.jpg\n",
       "2  00ffe211-568a-4345-ba25-0829863d0f7d.jpg\n",
       "3  006002a2-1345-4e49-97c5-f3b08f01852e.jpg\n",
       "4  003e5596-fa43-48ae-b5ce-5fd389d25128.jpg"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_crop = os.listdir(os.path.join(CWD_PATH,'image_samples/image_asli_added'))\n",
    "data_to_crop = pd.DataFrame(data_to_crop,columns=['filename'])\n",
    "data_to_crop.to_csv('/home/jupyter/gurih_mas/OCR/results/221018_filename_result.csv',index=False)\n",
    "print(data_to_crop.shape)\n",
    "data_to_crop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc503cb",
   "metadata": {},
   "source": [
    "## Localize Digit Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9874c2c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2022-10-21 04:18:38.127985: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -7 } dim { size: -10 } dim { size: -12 } dim { size: 576 } } } inputs { dtype: DT_FLOAT shape { dim { size: -37 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -37 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } tensor_content: \"\\016\\000\\000\\000\\016\\000\\000\\000\" } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"111\" frequency: 2199 num_cores: 4 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.3.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 57671680 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -37 } dim { size: 14 } dim { size: 14 } dim { size: 576 } } }\n",
      "100%|██████████| 300/300 [05:54<00:00,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "CWD_PATH = os.getcwd()\n",
    "image_path = os.path.join(CWD_PATH,'image_samples/image_asli_added')\n",
    "image_cropped_path = os.path.join(CWD_PATH,'image_samples/cropped_image')\n",
    "image_localized_path = os.path.join(CWD_PATH,'image_samples/localized_image')\n",
    "digit_dataset_path = os.path.join(CWD_PATH,'image_samples/digit_dataset')\n",
    "\n",
    "filename_list = []\n",
    "filename_crop_list = [] \n",
    "ymin_list = []\n",
    "ymax_list = []\n",
    "xmin_list = []\n",
    "xmax_list = []\n",
    "width_list = []\n",
    "height_list = []\n",
    "\n",
    "# IMAGE_NAME = '10b189c6-8a5a-400d-9734-1800be3466d4.jpg'\n",
    "\n",
    "for i in tqdm(range(data_to_crop.shape[0])):\n",
    "    IMAGE_NAME = data_to_crop.filename[i]\n",
    "    image_name_raw = IMAGE_NAME.split('.')[-2]\n",
    "    \n",
    "    # PATH_TO_IMAGE = os.path.join(CWD_PATH,'sampel_gambar','sample_data_real_test',IMAGE_NAME)\n",
    "    PATH_TO_IMAGE = os.path.join(image_path,IMAGE_NAME)\n",
    "    \n",
    "    image = cv2.imread(PATH_TO_IMAGE)\n",
    "    raw_image = cv2.imread(PATH_TO_IMAGE)\n",
    "    height, width, channels = image.shape\n",
    "    \n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_expanded = np.expand_dims(image_rgb, axis=0)\n",
    "    \n",
    "    (boxes, scores, classes, num) = sess.run(\n",
    "        [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "        feed_dict={image_tensor: image_expanded})\n",
    "\n",
    "    final_image, bbox = vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image,\n",
    "        np.squeeze(boxes),\n",
    "        np.squeeze(classes).astype(np.int32),\n",
    "        np.squeeze(scores),\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=3,\n",
    "        min_score_thresh=0.95)\n",
    "\n",
    "    # display(Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)))\n",
    "    im = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    im.save(image_localized_path+'/{}.jpg'.format(image_name_raw,i))\n",
    "\n",
    "    bbox.sort(reverse=False)\n",
    "\n",
    "    for i in range(len(bbox)):\n",
    "        xmin = bbox[i][0]\n",
    "        ymin = bbox[i][1]\n",
    "        xmax = bbox[i][2]\n",
    "        ymax = bbox[i][3]\n",
    "\n",
    "        filename_list.append(IMAGE_NAME)\n",
    "        ymin_list.append(ymin)\n",
    "        xmin_list.append(xmin)\n",
    "        ymax_list.append(ymax)\n",
    "        xmax_list.append(xmax)\n",
    "        width_list.append(width)\n",
    "        height_list.append(height)\n",
    "\n",
    "        cropped_img = raw_image[ymin:ymax,xmin:xmax]\n",
    "        rgb_cropped_img = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # display(Image.fromarray(rgb_cropped_img))\n",
    "        im_crop = Image.fromarray(rgb_cropped_img)\n",
    "        im_crop.save(image_cropped_path+'/{}_{}.jpg'.format(image_name_raw,i))\n",
    "        filename_crop_list.append('{}_{}.jpg'.format(image_name_raw,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14639652-13e2-447f-b1f2-dd09d530f254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cropped images: (3825, 2)\n"
     ]
    }
   ],
   "source": [
    "summary_df = pd.DataFrame([])\n",
    "summary_df['filename_ktp'] = filename_list\n",
    "summary_df['filename_digit'] = filename_crop_list\n",
    "print('Total cropped images: {}'.format(summary_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cbb7530-ca7a-46e8-ba3c-9491657db61d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_df.to_csv(os.path.join(CWD_PATH,'image_samples/221018_added_cropped_result.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e018bf7-2e32-4763-9a24-1b56d1392f01",
   "metadata": {},
   "source": [
    "## Predict Digit Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f43b29-7eff-4b27-8ff7-b5167bd6f9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3825 [00:00<?, ?it/s]2022-10-21 04:24:31.360449: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      " 27%|██▋       | 1041/3825 [00:59<02:28, 18.79it/s]"
     ]
    }
   ],
   "source": [
    "pred_label=[]\n",
    "scoring=[]\n",
    "\n",
    "for i in tqdm(range(len(filename_crop_list))):\n",
    "    image_filename = filename_crop_list[i]\n",
    "    image_full_path_dir = '{}/{}'.format(image_cropped_path, image_filename)\n",
    "\n",
    "    try:\n",
    "        pred_label_s, conf_score_s, model_score_s,score = get_prediction_s(image_full_path_dir, model)\n",
    "        pred_label.append(pred_label_s)\n",
    "        scoring.append(conf_score_s)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d095034-742e-4167-9972-3647b8ea8813",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_df['pred_score'] = scoring\n",
    "summary_df['pred_label'] = pred_label\n",
    "print('Predicted images: {}'.format(summary_df.shape))\n",
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0bd69b7-b1c7-4bf9-ba29-740eaab526ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_df.to_csv(os.path.join(CWD_PATH,'image_samples/221018_prediction_result.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6146cd28-5afe-42c1-94b7-b377e71bdba2",
   "metadata": {},
   "source": [
    "## Copy predicted images to each labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a93b555f-c9de-4859-85cd-a5b296a5fb0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_names = [str(i) for i in range(10)]\n",
    "\n",
    "for c in class_names:\n",
    "    if os.path.isdir(os.path.join(digit_dataset_path,c)) == False:\n",
    "        os.makedirs(os.path.join(digit_dataset_path,c))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df942272-050e-4c21-bd2e-c0f2202783f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16510/16510 [00:02<00:00, 6812.86it/s]\n"
     ]
    }
   ],
   "source": [
    "#Copy images based on labels\n",
    "\n",
    "for i in tqdm(range(summary_df.shape[0])):\n",
    "    img = summary_df['filename_digit'][i]\n",
    "    label = str(summary_df['pred_label'][i])\n",
    "    source_final_path = os.path.join(image_cropped_path,img)\n",
    "    dest_final_path = os.path.join(digit_dataset_path,label,img)\n",
    "    if os.path.isfile(dest_final_path) == False:\n",
    "        shutil.copy(source_final_path,dest_final_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b51965-7029-4cf1-b3b6-7b505a9ea210",
   "metadata": {},
   "source": [
    "## Summarize digit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a99c569-8903-43c1-9373-4dc74088c09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7010\n",
       "1    2171\n",
       "2    1048\n",
       "3    1941\n",
       "4     476\n",
       "5    1019\n",
       "6     641\n",
       "7    1154\n",
       "8     459\n",
       "9     591\n",
       "Name: pred_label, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df.pred_label.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f3f47c16-9859-4257-b059-0094896d322e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename_digit</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5842d07e-418f-44ce-af86-0d13a5a8984a_6.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4e7153a7-a7bf-4d4e-9ffd-a6ef2c84e1c3_3.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5c030af6-5f52-4ef0-99c7-309e9d753f52_0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5c030af6-5f52-4ef0-99c7-309e9d753f52_1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5c030af6-5f52-4ef0-99c7-309e9d753f52_3.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16505</th>\n",
       "      <td>e1b45bbe-3471-4d7c-983a-b439ef7de7e0_3.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16506</th>\n",
       "      <td>0167a3ba-873e-4940-b2ec-9e70427617d8_10.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16507</th>\n",
       "      <td>f47a3e70-f157-40c3-8614-f38914a5a951_9.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16508</th>\n",
       "      <td>01b9ce5a-74ca-4a18-8983-ed9da2eea67f_9.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16509</th>\n",
       "      <td>a9be7bf3-e41a-4e49-bc57-dbe159096e62_5.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16510 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    filename_digit  pred_label\n",
       "0       5842d07e-418f-44ce-af86-0d13a5a8984a_6.jpg           0\n",
       "1       4e7153a7-a7bf-4d4e-9ffd-a6ef2c84e1c3_3.jpg           0\n",
       "2       5c030af6-5f52-4ef0-99c7-309e9d753f52_0.jpg           0\n",
       "3       5c030af6-5f52-4ef0-99c7-309e9d753f52_1.jpg           0\n",
       "4       5c030af6-5f52-4ef0-99c7-309e9d753f52_3.jpg           0\n",
       "...                                            ...         ...\n",
       "16505   e1b45bbe-3471-4d7c-983a-b439ef7de7e0_3.jpg           9\n",
       "16506  0167a3ba-873e-4940-b2ec-9e70427617d8_10.jpg           9\n",
       "16507   f47a3e70-f157-40c3-8614-f38914a5a951_9.jpg           9\n",
       "16508   01b9ce5a-74ca-4a18-8983-ed9da2eea67f_9.jpg           9\n",
       "16509   a9be7bf3-e41a-4e49-bc57-dbe159096e62_5.jpg           9\n",
       "\n",
       "[16510 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_digit = summary_df.filter(['filename_digit','pred_label'], axis=1).sort_values('pred_label').reset_index(drop=True)\n",
    "df_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c1698b62-8522-4a42-bb9c-3dd2e99a0c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 5, 6, 7, 9]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = list(df_digit.pred_label.unique()) #Create a Python list of Unique labels in data frame labels\n",
    "class_names.remove(4)\n",
    "class_names.remove(8)\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e98aa5c2-2f1b-4f0b-9e87-575c1c752703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataframe into multiple dataframe based on unique column values\n",
    "dfdigit0 = df_digit.loc[df_digit['pred_label'] == 0]\n",
    "dfdigit0 = dfdigit0[0:500]\n",
    "dfdigit1 = df_digit.loc[df_digit['pred_label'] == 1]\n",
    "dfdigit1 = dfdigit1[0:500]\n",
    "dfdigit2 = df_digit.loc[df_digit['pred_label'] == 2]\n",
    "dfdigit2 = dfdigit2[0:500]\n",
    "dfdigit3 = df_digit.loc[df_digit['pred_label'] == 3]\n",
    "dfdigit3 = dfdigit3[0:500]\n",
    "dfdigit4 = df_digit.loc[df_digit['pred_label'] == 4]\n",
    "dfdigit5 = df_digit.loc[df_digit['pred_label'] == 5]\n",
    "dfdigit5 = dfdigit5[0:500]\n",
    "dfdigit6 = df_digit.loc[df_digit['pred_label'] == 6]\n",
    "dfdigit6 = dfdigit6[0:500]\n",
    "dfdigit7 = df_digit.loc[df_digit['pred_label'] == 7]\n",
    "dfdigit7 = dfdigit7[0:500]\n",
    "dfdigit8 = df_digit.loc[df_digit['pred_label'] == 8]\n",
    "dfdigit9 = df_digit.loc[df_digit['pred_label'] == 9]\n",
    "dfdigit9 = dfdigit9[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a8c0dae8-e458-49f1-af41-adc2f4f3149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting images for each PIC\n",
    "pic = ['Mas Kemas', 'Addin', 'Krisna', 'Rio', 'Vanda']\n",
    "list_pic = []\n",
    "\n",
    "for member in pic :\n",
    "    for i in range(100):\n",
    "        list_pic.append(member)\n",
    "\n",
    "dfdigit0['PIC'] = list_pic\n",
    "dfdigit1['PIC'] = list_pic\n",
    "dfdigit2['PIC'] = list_pic\n",
    "dfdigit3['PIC'] = list_pic\n",
    "dfdigit5['PIC'] = list_pic\n",
    "dfdigit6['PIC'] = list_pic\n",
    "dfdigit7['PIC'] = list_pic\n",
    "dfdigit9['PIC'] = list_pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "76ed4550-95a1-4f93-a5ac-924307f49cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "pic48 = ['Mas Kemas', 'Addin', 'Krisna', 'Rio']\n",
    "list_pic4=[]\n",
    "list_pic8=[]\n",
    "\n",
    "for member in pic48 :\n",
    "    for i in range(100):\n",
    "        list_pic4.append(member)\n",
    "\n",
    "for j in range(76):\n",
    "    list_pic4.append('Vanda')\n",
    "    \n",
    "for member in pic48 :\n",
    "    for i in range(100):\n",
    "        list_pic8.append(member)\n",
    "\n",
    "for j in range(59):\n",
    "    list_pic8.append('Vanda')\n",
    "\n",
    "dfdigit4['PIC'] = list_pic4\n",
    "dfdigit8['PIC'] = list_pic8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4db64dca-26ac-4e63-a096-dd90c72b7efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_dataset = pd.concat([dfdigit0, dfdigit1, dfdigit2, dfdigit3, dfdigit4, dfdigit5, dfdigit6, dfdigit7, dfdigit8, dfdigit9], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ce13b029-83e3-428b-b346-36cfbe60518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_dataset.to_csv('221018_Image_Samples.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "38ceeb76-21b3-48c2-83ec-fdb818afeeab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    500\n",
       "2    500\n",
       "3    500\n",
       "4    476\n",
       "5    500\n",
       "6    500\n",
       "7    500\n",
       "8    459\n",
       "9    500\n",
       "Name: pred_label, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_dataset.pred_label.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "74b5dca3-ecf0-4d50-97f7-692a8494e88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Addin        1000\n",
       "Krisna       1000\n",
       "Mas Kemas    1000\n",
       "Rio          1000\n",
       "Vanda         935\n",
       "Name: PIC, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_dataset.PIC.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "525f82e8-792a-4d06-9f5c-be5781653504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename_digit</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>PIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5842d07e-418f-44ce-af86-0d13a5a8984a_6.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Mas Kemas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4e7153a7-a7bf-4d4e-9ffd-a6ef2c84e1c3_3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Mas Kemas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5c030af6-5f52-4ef0-99c7-309e9d753f52_0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Mas Kemas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5c030af6-5f52-4ef0-99c7-309e9d753f52_1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Mas Kemas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5c030af6-5f52-4ef0-99c7-309e9d753f52_3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Mas Kemas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4930</th>\n",
       "      <td>01939003-2e65-4cea-b732-ef7162860d59_15.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>Vanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>01cb6fd3-1e6e-48a3-b32f-bbaf8bc9b816_5.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>Vanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4932</th>\n",
       "      <td>354f4e1c-5906-44ca-8ee0-b3d8aa99352c_11.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>Vanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4933</th>\n",
       "      <td>01b66808-6057-42e7-9e61-e367fa1858e5_10.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>Vanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4934</th>\n",
       "      <td>00e8f929-b97c-4dd7-b34e-dd63a497f642_2.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>Vanda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4935 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   filename_digit  pred_label        PIC\n",
       "0      5842d07e-418f-44ce-af86-0d13a5a8984a_6.jpg           0  Mas Kemas\n",
       "1      4e7153a7-a7bf-4d4e-9ffd-a6ef2c84e1c3_3.jpg           0  Mas Kemas\n",
       "2      5c030af6-5f52-4ef0-99c7-309e9d753f52_0.jpg           0  Mas Kemas\n",
       "3      5c030af6-5f52-4ef0-99c7-309e9d753f52_1.jpg           0  Mas Kemas\n",
       "4      5c030af6-5f52-4ef0-99c7-309e9d753f52_3.jpg           0  Mas Kemas\n",
       "...                                           ...         ...        ...\n",
       "4930  01939003-2e65-4cea-b732-ef7162860d59_15.jpg           9      Vanda\n",
       "4931   01cb6fd3-1e6e-48a3-b32f-bbaf8bc9b816_5.jpg           9      Vanda\n",
       "4932  354f4e1c-5906-44ca-8ee0-b3d8aa99352c_11.jpg           9      Vanda\n",
       "4933  01b66808-6057-42e7-9e61-e367fa1858e5_10.jpg           9      Vanda\n",
       "4934   00e8f929-b97c-4dd7-b34e-dd63a497f642_2.jpg           9      Vanda\n",
       "\n",
       "[4935 rows x 3 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "476a82db-0b3e-4c62-96a9-f5759382170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for each PIC\n",
    "class_names = [str(i) for i in range(10)]\n",
    "pic = ['Mas Kemas', 'Addin', 'Krisna', 'Rio', 'Vanda']\n",
    "\n",
    "for p in pic:\n",
    "    for c in class_names:\n",
    "        if os.path.isdir(os.path.join('/home/jupyter/OCR/addin/digit_localization_prediction_model/sampel_gambar/221018_dataset',p,c)) == False:\n",
    "            os.makedirs(os.path.join('/home/jupyter/OCR/addin/digit_localization_prediction_model/sampel_gambar/221018_dataset',p,c))\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e2535ec6-4590-451f-afad-5525d7e77c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4935/4935 [00:00<00:00, 7210.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Copy images based on PIC\n",
    "\n",
    "dest_path = '/home/jupyter/OCR/addin/digit_localization_prediction_model/sampel_gambar/221018_dataset'\n",
    "\n",
    "for i in tqdm(range(filename_dataset.shape[0])):\n",
    "    img = filename_dataset['filename_digit'][i]\n",
    "    pic = filename_dataset['PIC'][i]\n",
    "    label = str(filename_dataset['pred_label'][i])\n",
    "    source_final_path = os.path.join(image_cropped_path,img)\n",
    "    dest_final_path = os.path.join(dest_path,pic,label,img)\n",
    "    if os.path.isfile(dest_final_path) == False:\n",
    "        shutil.copy(source_final_path,dest_final_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "defa3648-0e3e-4418-96df-d2168c937c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "pic = ['Mas Kemas', 'Addin', 'Krisna', 'Rio', 'Vanda']\n",
    "\n",
    "def zipdir(path, ziph):\n",
    "    # ziph is zipfile handle\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            ziph.write(os.path.join(root, file), \n",
    "                       os.path.relpath(os.path.join(root, file), \n",
    "                                       os.path.join(path, '..')))\n",
    "\n",
    "for p in pic :\n",
    "    with zipfile.ZipFile('/home/jupyter/OCR/addin/digit_localization_prediction_model/{}.zip'.format(p), 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        zipdir('/home/jupyter/OCR/addin/digit_localization_prediction_model/sampel_gambar/221018_dataset/{}'.format(p), zipf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6f3c155-dc12-4800-90a0-9bf553fbe44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def zipdir(path, ziph):\n",
    "    # ziph is zipfile handle\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            ziph.write(os.path.join(root, file), \n",
    "                       os.path.relpath(os.path.join(root, file), \n",
    "                                       os.path.join(path, '..')))\n",
    "\n",
    "with zipfile.ZipFile('/home/jupyter/OCR/addin/inf_graph.zip', 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    zipdir('/home/jupyter/OCR/addin/digit_localization_prediction_model/inference_graph', zipf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d2f632-1377-42a6-858d-68d491eb33a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
